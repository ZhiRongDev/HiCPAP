{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook is for comparing the time spent of the PCA (Only calculate the first PC using the [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)) versus our estimation method. We use the PC1 created by juicer_tools as the ground truth (GM12878, chromosome 2, resolution 25Kb), which we call it the `juicer_pc1_np`, for comparing the `similar_rate` between tracks (e.g. The Scikit-learn created PC1 versus the `juicer_pc1_np`, and the Estimated PC1-pattern versus the `juicer_pc1_np`). The `similar_rate` is defined as the proportion of the entries in the track1 (e.g. `juicer_pc1_np`) that have a same positive/negative sign as the track2 (e.g. Estimated PC1-pattern) entries compared.\n",
    "\n",
    "Note that you will have to take a few hours to create the ground truth `juicer_pc1_np` using the juicer_tools in advance, (In our cases, over 4 hours), besides the calculation is only performed on the not `NaN` entries in this notebook.\n",
    "\n",
    "In summarize, we find that the sign-pattern of the PC1 created by juicer_tools or Scikit-learn are slightly different, the `similar_rate` between the Scikit-learn calculated PC1 versus the Estimated PC1-pattern are higher than the `juicer_pc1_np` versus the Estimated PC1-pattern. Further more, we found that most of the columns in the Hi-C Pearson's covariance matrix are suitable for being selected as the Estimated PC1-pattern, since most of them has a `similar_rate` over 95% versus the ground truth `juicer_pc1_np`, hence we might utilize the random sampling to speed up and reduce the memory requirement of the covariance matrix calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the path for your GM12878, Chromosome 2, 25Kb Pearson matrix & PC1 text file created by juicer_tools.\n",
    "pearson_path = \"./data/gm12878_pearson_25000_chr2.txt\"\n",
    "pc1_path = \"./data/gm12878_pc1_25000_chr2.txt\" # Ground Truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from random import sample\n",
    "from sklearn.decomposition import PCA\n",
    "from hicpep import peptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to flip the sign of the PC1 or Estimated PC1-pattern according to the reference genome's GC-content distribution. The reference genome we used in this notebook is the GRCh37 (hg19) assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_track_gc(track_np: np.ndarray, gc_np: np.ndarray) -> np.ndarray:\n",
    "    if np.nanmean(gc_np[track_np[:-1] > 0]) < np.nanmean(gc_np[track_np[:-1] < 0]):\n",
    "        track_np = -track_np\n",
    "    return track_np\n",
    "\n",
    "gc_df = pd.read_table(\"./data/hg19_gc25000_chr2.txt\", skiprows=[0], names=[\"bin\", \"GC\"])\n",
    "gc_np = gc_df[\"GC\"].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the juicer_tools created Pearson correlation matrix and remove the `NaN` entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_np = peptools.read_pearson(pearson=pearson_path)\n",
    "\n",
    "if len(pearson_np) != len(pearson_np[0]):\n",
    "    print(\"Pearson matrix has a different number of rows and columns\")\n",
    "\n",
    "pearson_np = pearson_np.astype('float64')\n",
    "diag = np.diag(pearson_np)\n",
    "diag_valid = ~np.isnan(diag)\n",
    "ixgrid = np.ix_(diag_valid, diag_valid) # Record the position of the valid sub-matrix. \n",
    "pearson_np = pearson_np[ixgrid]\n",
    "valid_entry_num = len(pearson_np)\n",
    "\n",
    "has_nan = np.isnan(pearson_np).any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"NaN entries still exist in the Pearson matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the juicer_tools created PC1 as the comparison ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "juicer_pc1_df = pd.read_table(pc1_path, header=None)\n",
    "juicer_pc1_np = juicer_pc1_df.values.flatten()\n",
    "juicer_pc1_np = flip_track_gc(track_np=juicer_pc1_np, gc_np=gc_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the time spent for PCA if we only calculate the first Principal component through Scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for performing PCA through Scikit-learn to get the PC1 (seconds): 3.9339442253112793\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(pearson_np)\n",
    "# Place back the valid entries to it's origin position in the chromosome.\n",
    "pc1_np = np.full(len(diag_valid), np.nan)\n",
    "pc1_np[diag_valid] = pca.components_[0]\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time spent for performing PCA through Scikit-learn to get the PC1 (seconds): {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the time spent for creating the Estimated PC1-pattern if we:\n",
    "1. Construct the covariance matrix of a centered Pearson correlation matrix.\n",
    "2. Select the row (same as selecting the column, since the covariance matrix is symmetric) of covariance matrix with the maximum summation of the absolute-value of each entry as the estimate PC1-pattern (We defined as $CxMax$ in our paper).   \n",
    "\n",
    "Assume we use $X_{d \\times d}$ to denote the centered Pearson correlation matrix ($d$ means the number of bins), then the formula for constructing the covariance matrix will be $\\frac{1}{n}XX^{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for creating the Estimated PC1-pattern by finding the CxMax in the full-covariance matrix (seconds): 11.042360782623291\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pearson_np -= pearson_np.mean(axis=1, keepdims=True)\n",
    "n = len(pearson_np[0])\n",
    "cov_np = pearson_np @ pearson_np.T / n\n",
    "cov_abs_sum = [(index, np.sum(np.abs(row))) for index, row in enumerate(cov_np)] \n",
    "sorted_cov_abs_sum = sorted(cov_abs_sum, key=lambda x: x[1], reverse=True) # Sorted from the maximum to the minimum. \n",
    "# Place back the valid entries to it's origin position in the chromosome.\n",
    "est_np = np.full(len(diag_valid), np.nan)\n",
    "est_np[diag_valid] = cov_np[sorted_cov_abs_sum[0][0]]\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time spent for creating the Estimated PC1-pattern by finding the CxMax in the full-covariance matrix (seconds): {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the similar_rate between the `juicer_pc1_np` and the Scikit-learn created PC1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_entry_num: 9728\n",
      "valid_entry_num: 9519\n",
      "similar_num: 9130\n",
      "similar_rate: 0.959\n"
     ]
    }
   ],
   "source": [
    "pc1_np = flip_track_gc(track_np=pc1_np, gc_np=gc_np)\n",
    "similar_info = peptools.calc_similarity(track1_np=juicer_pc1_np, track2_np=pc1_np)\n",
    "\n",
    "print(f\"total_entry_num: {similar_info['total_entry_num']}\")\n",
    "print(f\"valid_entry_num: {similar_info['valid_entry_num']}\")\n",
    "print(f\"similar_num: {similar_info['similar_num']}\")\n",
    "print(f\"similar_rate: {np.round(similar_info['similar_rate'], 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the similar_rate between the `juicer_pc1_np` and the Estimated PC1-pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_entry_num: 9728\n",
      "valid_entry_num: 9519\n",
      "similar_num: 9234\n",
      "similar_rate: 0.97\n"
     ]
    }
   ],
   "source": [
    "est_np = flip_track_gc(track_np=est_np, gc_np=gc_np)\n",
    "similar_info = peptools.calc_similarity(track1_np=juicer_pc1_np, track2_np=est_np)\n",
    "\n",
    "print(f\"total_entry_num: {similar_info['total_entry_num']}\")\n",
    "print(f\"valid_entry_num: {similar_info['valid_entry_num']}\")\n",
    "print(f\"similar_num: {similar_info['similar_num']}\")\n",
    "print(f\"similar_rate: {np.round(similar_info['similar_rate'], 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the similar_rate between the Scikit learn created PC1 and the Estimated PC1-pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_entry_num: 9728\n",
      "valid_entry_num: 9519\n",
      "similar_num: 9361\n",
      "similar_rate: 0.983\n"
     ]
    }
   ],
   "source": [
    "similar_info = peptools.calc_similarity(track1_np=pc1_np, track2_np=est_np)\n",
    "\n",
    "print(f\"total_entry_num: {similar_info['total_entry_num']}\")\n",
    "print(f\"valid_entry_num: {similar_info['valid_entry_num']}\")\n",
    "print(f\"similar_num: {similar_info['similar_num']}\")\n",
    "print(f\"similar_rate: {np.round(similar_info['similar_rate'], 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since creating the Estimated PC1-pattern is merely selecting one of the columns of the covariance matrix (i.e. $CxMax$), we compute the `similar_rate` between the `juicer_pc1_np` and each column of the covariance matrix. We found that over 91% of these columns have a `similar_rate` higher than 0.9, over 72% have a `similar_rate` higher than 0.95, but 0% have a `similar_rate` higher than 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_entry_num: 9519\n",
      "similar_rate over 0.9: 91.879%\n",
      "similar_rate over 0.95: 72.959%\n",
      "similar_rate over 0.99: 0.0%\n"
     ]
    }
   ],
   "source": [
    "similar_rates_over90 = []\n",
    "similar_rates_over95 = []\n",
    "similar_rates_over99 = []\n",
    "\n",
    "for i in range(len(cov_np)):\n",
    "    # Place back the valid entries to it's origin position in the chromosome.  \n",
    "    est_np = np.full(len(diag_valid), np.nan)\n",
    "    est_np[diag_valid] = cov_np[i]\n",
    "    est_np = flip_track_gc(track_np=est_np, gc_np=gc_np)\n",
    "    similar_info = peptools.calc_similarity(track1_np=juicer_pc1_np, track2_np=est_np)\n",
    "\n",
    "    if similar_info[\"similar_rate\"] >= 0.9:\n",
    "        similar_rates_over90.append(similar_info[\"similar_rate\"])\n",
    "    \n",
    "    if similar_info[\"similar_rate\"] >= 0.95:\n",
    "        similar_rates_over95.append(similar_info[\"similar_rate\"])\n",
    "    \n",
    "    if similar_info[\"similar_rate\"] >= 0.99:\n",
    "        similar_rates_over99.append(similar_info[\"similar_rate\"])\n",
    "\n",
    "print(f\"valid_entry_num: {valid_entry_num}\")\n",
    "print(f\"similar_rate over 0.9: {np.round(len(similar_rates_over90) / valid_entry_num * 100, 3)}%\")\n",
    "print(f\"similar_rate over 0.95: {np.round(len(similar_rates_over95) / valid_entry_num * 100, 3)}%\")\n",
    "print(f\"similar_rate over 0.99: {np.round(len(similar_rates_over99) / valid_entry_num * 100, 3)}%\")\n",
    "# print(f\"Actual values of similar_rate > 0.9: {similar_rates_over90 + similar_rates_over95 + similar_rates_over99}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compare the `similar_rate` between the the Scikit-learn created PC1 and our Estimated PC1-pattern, over 92% of these columns have a `similar_rate` higher than 0.9, over 84% have a `similar_rate` higher than 0.95, and over 36% have a `similar_rate` higher than 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_entry_num: 9519\n",
      "similar_rate over 0.9: 92.426%\n",
      "similar_rate over 0.95: 84.652%\n",
      "similar_rate over 0.99: 36.338%\n"
     ]
    }
   ],
   "source": [
    "similar_rates_over90 = []\n",
    "similar_rates_over95 = []\n",
    "similar_rates_over99 = []\n",
    "\n",
    "for i in range(len(cov_np)):\n",
    "    # Place back the valid entries to it's origin position in the chromosome.  \n",
    "    est_np = np.full(len(diag_valid), np.nan)\n",
    "    est_np[diag_valid] = cov_np[i]\n",
    "    est_np = flip_track_gc(track_np=est_np, gc_np=gc_np)\n",
    "    similar_info = peptools.calc_similarity(track1_np=pc1_np, track2_np=est_np)\n",
    "\n",
    "    if similar_info[\"similar_rate\"] >= 0.9:\n",
    "        similar_rates_over90.append(similar_info[\"similar_rate\"])\n",
    "    \n",
    "    if similar_info[\"similar_rate\"] >= 0.95:\n",
    "        similar_rates_over95.append(similar_info[\"similar_rate\"])\n",
    "\n",
    "    if similar_info[\"similar_rate\"] >= 0.99:\n",
    "        similar_rates_over99.append(similar_info[\"similar_rate\"])\n",
    "\n",
    "print(f\"valid_entry_num: {valid_entry_num}\")\n",
    "print(f\"similar_rate over 0.9: {np.round(len(similar_rates_over90) / valid_entry_num * 100, 3)}%\")\n",
    "print(f\"similar_rate over 0.95: {np.round(len(similar_rates_over95) / valid_entry_num * 100, 3)}%\")\n",
    "print(f\"similar_rate over 0.99: {np.round(len(similar_rates_over99) / valid_entry_num * 100, 3)}%\")\n",
    "# print(f\"Actual values of similar_rate > 0.9: {similar_rates_over90 + similar_rates_over95 + similar_rates_over99}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiments above illustrate the difference between the PC1 created by different method or package, hence the result of the compartment identification might always be slightly inconsistent using the PC1-based method, which means the a little loss in the `similar_rate` between the `juicer_tools` and our Estimated PC1-pattern might also be acceptable.\n",
    "\n",
    "Besides, these experiment show that if we randomly select $k$ rows of the Pearson correlation matrix and denote as $V_{k \\times d}$, and perform the 'partial' covariance matrix calculation (which means $\\frac{1}{n}XV^{T}$), the chance that the partial covariance matrix contains tracks that have a `similar_rate` higher than 0.95 is pretty high, hence it will speed up the calculation for finding an appropriate track as the Estimated PC1-pattern. \n",
    "\n",
    "Here we show the time spent for creating the Estimated PC1-Pattern by finding the $CxMax$ in the partial covariance matrix through sampling. Assume that we randomly sample 10% of the rows in the Pearson matrix for constructing the partial covariance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for creating the Estimated PC1-pattern by finding the CxMax in the partial-covariance matrix through sampling (seconds): 3.3456642627716064\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "n = len(pearson_np[0])\n",
    "sample_indexes = sample(list(range(n)), math.floor(n * 0.1))\n",
    "\n",
    "partial_cov_np = pearson_np @ pearson_np[sample_indexes].T / n\n",
    "partial_cov_abs_sum = [(index, np.sum(np.abs(row))) for index, row in enumerate(partial_cov_np.T)] \n",
    "sorted_partial_cov_abs_sum = sorted(partial_cov_abs_sum, key=lambda x: x[1], reverse=True) # Sorted from the maximum to the minimum \n",
    "\n",
    "est_np = np.full(len(diag_valid), np.nan)\n",
    "est_np[diag_valid] = partial_cov_np.T[sorted_partial_cov_abs_sum[0][0]]\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time spent for creating the Estimated PC1-pattern by finding the CxMax in the partial-covariance matrix through sampling (seconds): {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we compare the similar_rate between the `juicer_pc1_np` and the Estimated PC1-pattern created by finding the $CxMax$ in the partial-covariance matrix through sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_entry_num: 9728\n",
      "valid_entry_num: 9519\n",
      "similar_num: 9234\n",
      "similar_rate: 0.97\n"
     ]
    }
   ],
   "source": [
    "est_np = flip_track_gc(track_np=est_np, gc_np=gc_np)\n",
    "similar_info = peptools.calc_similarity(track1_np=juicer_pc1_np, track2_np=est_np)\n",
    "\n",
    "print(f\"total_entry_num: {similar_info['total_entry_num']}\")\n",
    "print(f\"valid_entry_num: {similar_info['valid_entry_num']}\")\n",
    "print(f\"similar_num: {similar_info['similar_num']}\")\n",
    "print(f\"similar_rate: {np.round(similar_info['similar_rate'], 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
